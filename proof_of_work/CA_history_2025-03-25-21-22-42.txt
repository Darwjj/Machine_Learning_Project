2025-03-25-21-22-42 163 1 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set()     while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3))         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA)  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         ex, ey, esize, etype = shape["center"][0], shape["center"][1], shape["size"], shape["type"]          if etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - ex) ** 2 + (y - ey) ** 2)             if distance < (size + esize):                   return True  # Overlap detected          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - ex) < (size + esize) and abs(y - ey) < (size + esize):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw filled circle     return np.pi * (size ** 2)  # Compute area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_left = (center[0] - size, center[1] - size)     bottom_right = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_left, bottom_right, color, -1)  # Draw filled square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle_cnt = np.array([point1, point2, point3])  # Convert to NumPy array     cv2.fillPoly(image, [triangle_cnt], color)  # Draw filled triangle      # Compute triangle area (equilateral)     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height  # (1/2 * base * height)   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []  # To store details of added shapes      # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Avoid infinite loops         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps with existing ones             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store shape metadata                 shapes_metadata.append({"type": shape_type, "center": center, "size": size, "area": area})                 break  # Move to the next shape          # Resize the image to num_pixels x num_pixels     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     raise NotImplementedError()  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     raise NotImplementedError()  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     raise NotImplementedError()      save_history()
2025-03-25-21-22-42 163 2 get_ipython().run_line_magic('matplotlib', 'inline') import matplotlib.pyplot as plt import numpy as np import scipy as sp import cv2 import random import pandas as pd from typing import List, Tuple, Callable, Optional from submission_utils import save_history, check_and_prepare_for_submission # import warnings filter from warnings import simplefilter # ignore all future warnings simplefilter(action='ignore', category=FutureWarning)
2025-03-25-21-22-42 163 3 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set()     while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3))         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA)  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         ex, ey, esize, etype = shape["center"][0], shape["center"][1], shape["size"], shape["type"]          if etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - ex) ** 2 + (y - ey) ** 2)             if distance < (size + esize):                   return True  # Overlap detected          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - ex) < (size + esize) and abs(y - ey) < (size + esize):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw filled circle     return np.pi * (size ** 2)  # Compute area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_left = (center[0] - size, center[1] - size)     bottom_right = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_left, bottom_right, color, -1)  # Draw filled square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle_cnt = np.array([point1, point2, point3])  # Convert to NumPy array     cv2.fillPoly(image, [triangle_cnt], color)  # Draw filled triangle      # Compute triangle area (equilateral)     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height  # (1/2 * base * height)   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []  # To store details of added shapes      # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Avoid infinite loops         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps with existing ones             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store shape metadata                 shapes_metadata.append({"type": shape_type, "center": center, "size": size, "area": area})                 break  # Move to the next shape          # Resize the image to num_pixels x num_pixels     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     raise NotImplementedError()  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     raise NotImplementedError()  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     raise NotImplementedError()      save_history()
2025-03-25-21-22-42 163 4 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set()     while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3))         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA)  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         ex, ey, esize, etype = shape["center"][0], shape["center"][1], shape["size"], shape["type"]          if etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - ex) ** 2 + (y - ey) ** 2)             if distance < (size + esize):                   return True  # Overlap detected          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - ex) < (size + esize) and abs(y - ey) < (size + esize):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw filled circle     return np.pi * (size ** 2)  # Compute area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_left = (center[0] - size, center[1] - size)     bottom_right = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_left, bottom_right, color, -1)  # Draw filled square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle_cnt = np.array([point1, point2, point3])  # Convert to NumPy array     cv2.fillPoly(image, [triangle_cnt], color)  # Draw filled triangle      # Compute triangle area (equilateral)     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height  # (1/2 * base * height)   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []  # To store details of added shapes      # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Avoid infinite loops         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps with existing ones             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store shape metadata                 shapes_metadata.append({"type": shape_type, "center": center, "size": size, "area": area})                 break  # Move to the next shape          # Resize the image to num_pixels x num_pixels     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     # Extract areas of circles and squares     max_circle_area = max((shape["area"] for shape in shapes_metadata if shape["type"] == "circle"), default=0)     max_square_area = max((shape["area"] for shape in shapes_metadata if shape["type"] == "square"), default=0)      # Compare areas     if max_square_area > (1 + fraction) * max_circle_area:         return 0  # Square is much larger     elif max_circle_area > (1 + fraction) * max_square_area:         return 2  # Circle is much larger     else:         return 1  # They are similar in size  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     # Step 1: Generate a color palette     color_palette = generate_color_palette(num_colors)      # Step 2: Initialize storage     X = np.zeros((num_samples, num_pixels, num_pixels, 3), dtype=np.uint8)  # Image storage     y = np.zeros(num_samples, dtype=np.int32)  # Label storage      # Step 3: Generate images and labels     for i in range(num_samples):         image, shapes_metadata = generate_image(img_size, num_pixels, color_palette, max_shapes)         label = assign_label(shapes_metadata, fraction)                  # Store results         X[i] = image         y[i] = label          # Print progress         if i % 100 == 0:             print(f"Generated {i}/{num_samples} images...")      print("Dataset generation complete!")     return X, y  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     raise NotImplementedError()      save_history()
2025-03-25-21-22-42 163 5 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set()     while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3))         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA)  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         ex, ey, esize, etype = shape["center"][0], shape["center"][1], shape["size"], shape["type"]          if etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - ex) ** 2 + (y - ey) ** 2)             if distance < (size + esize):                   return True  # Overlap detected          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - ex) < (size + esize) and abs(y - ey) < (size + esize):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw filled circle     return np.pi * (size ** 2)  # Compute area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_left = (center[0] - size, center[1] - size)     bottom_right = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_left, bottom_right, color, -1)  # Draw filled square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle_cnt = np.array([point1, point2, point3])  # Convert to NumPy array     cv2.fillPoly(image, [triangle_cnt], color)  # Draw filled triangle      # Compute triangle area (equilateral)     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height  # (1/2 * base * height)   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []  # To store details of added shapes      # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Avoid infinite loops         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps with existing ones             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store shape metadata                 shapes_metadata.append({"type": shape_type, "center": center, "size": size, "area": area})                 break  # Move to the next shape          # Resize the image to num_pixels x num_pixels     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     # Extract areas of circles and squares     max_circle_area = max((shape["area"] for shape in shapes_metadata if shape["type"] == "circle"), default=0)     max_square_area = max((shape["area"] for shape in shapes_metadata if shape["type"] == "square"), default=0)      # Compare areas     if max_square_area > (1 + fraction) * max_circle_area:         return 0  # Square is much larger     elif max_circle_area > (1 + fraction) * max_square_area:         return 2  # Circle is much larger     else:         return 1  # They are similar in size  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     # Step 1: Generate a color palette     color_palette = generate_color_palette(num_colors)      # Step 2: Initialize storage     X = np.zeros((num_samples, num_pixels, num_pixels, 3), dtype=np.uint8)  # Image storage     y = np.zeros(num_samples, dtype=np.int32)  # Label storage      # Step 3: Generate images and labels     for i in range(num_samples):         image, shapes_metadata = generate_image(img_size, num_pixels, color_palette, max_shapes)         label = assign_label(shapes_metadata, fraction)                  # Store results         X[i] = image         y[i] = label          # Print progress         if i % 100 == 0:             print(f"Generated {i}/{num_samples} images...")      print("Dataset generation complete!")     return X, y  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     unique_labels = np.unique(y)  # Get all unique class labels     num_classes = len(unique_labels)      fig, axes = plt.subplots(num_classes, num_samples, figsize=(num_samples * 2, num_classes * 2))          for i, label in enumerate(unique_labels):         # Get indices of images belonging to the current class         indices = np.where(y == label)[0]                  # Select `num_samples` images randomly (or fewer if not enough available)         selected_indices = np.random.choice(indices, min(num_samples, len(indices)), replace=False)          for j, idx in enumerate(selected_indices):             ax = axes[i, j] if num_classes > 1 else axes[j]  # Adjust for 1-row cases             ax.imshow(X[idx])  # Display the image             ax.axis("off")  # Hide axis             ax.set_title(f"Label: {label}", fontsize=10)      plt.tight_layout()     plt.show()      save_history()
2025-03-25-21-22-42 163 6 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 7 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 8 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 9 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 10 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 11 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 12 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 13 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 14 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 15 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 16 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
2025-03-25-21-22-42 163 17 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
2025-03-25-21-22-42 163 18 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
2025-03-25-21-22-42 163 19 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
2025-03-25-21-22-42 163 20 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     raise NotImplementedError()  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     raise NotImplementedError()  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     raise NotImplementedError()  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     raise NotImplementedError()  def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 21 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 22 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative true positives     cumulative_tp = np.cumsum(sorted_targets)     total_positives = np.sum(targets)          # Compute TPR values     tpr_values = cumulative_tp / total_positives if total_positives > 0 else np.zeros_like(cumulative_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     raise NotImplementedError()  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     raise NotImplementedError()  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     raise NotImplementedError()  def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 23 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative true positives     cumulative_tp = np.cumsum(sorted_targets)     total_positives = np.sum(targets)          # Compute TPR values     tpr_values = cumulative_tp / total_positives if total_positives > 0 else np.zeros_like(cumulative_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative false positives     cumulative_fp = np.cumsum(1 - sorted_targets)     total_negatives = np.sum(1 - targets)          # Compute FPR values     fpr_values = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)          return fpr_values  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     raise NotImplementedError()  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     raise NotImplementedError()  def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 24 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative true positives     cumulative_tp = np.cumsum(sorted_targets)     total_positives = np.sum(targets)          # Compute TPR values     tpr_values = cumulative_tp / total_positives if total_positives > 0 else np.zeros_like(cumulative_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative false positives     cumulative_fp = np.cumsum(1 - sorted_targets)     total_negatives = np.sum(1 - targets)          # Compute FPR values     fpr_values = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)          return fpr_values  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     return np.trapz(TPR, FPR)  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     raise NotImplementedError()  def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 25 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative true positives     cumulative_tp = np.cumsum(sorted_targets)     total_positives = np.sum(targets)          # Compute TPR values     tpr_values = cumulative_tp / total_positives if total_positives > 0 else np.zeros_like(cumulative_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative false positives     cumulative_fp = np.cumsum(1 - sorted_targets)     total_negatives = np.sum(1 - targets)          # Compute FPR values     fpr_values = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)          return fpr_values  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     return np.trapz(TPR, FPR)  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     tpr_all = np.array([true_positive_rate_func(scores, y_test) for scores in scores_list])     fpr_all = np.array([false_positive_rate_func(scores, y_test) for scores in scores_list])      tpr_low = np.quantile(tpr_all, low_quantile, axis=0)     tpr_high = np.quantile(tpr_all, high_quantile, axis=0)     tpr_mid = np.median(tpr_all, axis=0)     fpr_median = np.median(fpr_all, axis=0)      return tpr_low.tolist(), tpr_high.tolist(), tpr_mid.tolist(), fpr_median.tolist()   def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 26 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative true positives     cumulative_tp = np.cumsum(sorted_targets)     total_positives = np.sum(targets)          # Compute TPR values     tpr_values = cumulative_tp / total_positives if total_positives > 0 else np.zeros_like(cumulative_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative false positives     cumulative_fp = np.cumsum(1 - sorted_targets)     total_negatives = np.sum(1 - targets)          # Compute FPR values     fpr_values = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)          return fpr_values  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     return np.trapz(TPR, FPR)  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     tpr_all = np.array([true_positive_rate_func(scores, y_test) for scores in scores_list])     fpr_all = np.array([false_positive_rate_func(scores, y_test) for scores in scores_list])      tpr_low = np.quantile(tpr_all, low_quantile, axis=0)     tpr_high = np.quantile(tpr_all, high_quantile, axis=0)     tpr_mid = np.median(tpr_all, axis=0)     fpr_median = np.median(fpr_all, axis=0)      return tpr_low.tolist(), tpr_high.tolist(), tpr_mid.tolist(), fpr_median.tolist()   def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     plt.figure(figsize=(8, 6))     plt.plot(fpr, tpr_mid, marker='o', linestyle='-', color='black', label="Median TPR")     plt.fill_between(fpr, tpr_low, tpr_high, color='b', alpha=0.3, label='Confidence Interval')     plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Random Classifier")     plt.xlabel('False Positive Rate (FPR)')     plt.ylabel('True Positive Rate (TPR)')     plt.title(f"AUC ROC: {compute_auc_func(tpr_mid, fpr):.2f}")     plt.legend(loc="lower right")     plt.grid()     plt.show()      save_history()
2025-03-25-21-22-42 163 27 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 28 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 29 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 30 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 31 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 32 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 33 test_tpr_low = [0.04, 0.73, 0.86, 0.91, 1] test_tpr_high = [0.30, 0.91, 0.95, 1.0, 1] test_tpr_mid = [0.08, 0.82, 0.91, 0.95, 1] test_fpr = [0.0, 0.25, 0.51, 0.77, 1]  plot_roc(np.array(test_tpr_low), np.array(test_tpr_high), np.array(test_tpr_mid), np.array(test_fpr), compute_auc)      
2025-03-25-21-22-42 163 34 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     raise NotImplementedError()  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     raise NotImplementedError()  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     raise NotImplementedError()  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     raise NotImplementedError()   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 35 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_area = np.sum(areas)          if total_area == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     raise NotImplementedError()  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     raise NotImplementedError()  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     raise NotImplementedError()   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 36 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_area = np.sum(areas)          if total_area == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     features = compute_color_features(patch, ignore_color)     return aggregate_features(features)  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     raise NotImplementedError()  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     raise NotImplementedError()   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 37 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_area = np.sum(areas)          if total_area == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     features = compute_color_features(patch, ignore_color)     return aggregate_features(features)  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     h, w, _ = image.shape     patch_h, patch_w = h // grid_size, w // grid_size          descriptors = np.zeros((grid_size, grid_size, 7))          for i in range(grid_size):         for j in range(grid_size):             patch = image[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]             descriptors[i, j] = compute_patch_descriptor(patch, ignore_color)          return descriptors  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     raise NotImplementedError()   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 38 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_area = np.sum(areas)          if total_area == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     features = compute_color_features(patch, ignore_color)     return aggregate_features(features)  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     h, w, _ = image.shape     patch_h, patch_w = h // grid_size, w // grid_size          descriptors = np.zeros((grid_size, grid_size, 7))          for i in range(grid_size):         for j in range(grid_size):             patch = image[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]             descriptors[i, j] = compute_patch_descriptor(patch, ignore_color)          return descriptors  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     descriptors1 = compute_image_patch_descriptors(image1, grid_size, ignore_color)     descriptors2 = compute_image_patch_descriptors(image2, grid_size, ignore_color)          total_similarity = np.sum(np.exp(-np.linalg.norm(descriptors1[:, :, None, :] - descriptors2[None, None, :, :], axis=-1)))     return total_similarity   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 39 get_ipython().run_line_magic('matplotlib', 'inline') import matplotlib.pyplot as plt import numpy as np import scipy as sp import cv2 import random import pandas as pd from typing import List, Tuple, Callable, Optional from submission_utils import save_history, check_and_prepare_for_submission # import warnings filter from warnings import simplefilter # ignore all future warnings simplefilter(action='ignore', category=FutureWarning)
2025-03-25-21-22-42 163 40 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set()     while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3))         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA)  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         ex, ey, esize, etype = shape["center"][0], shape["center"][1], shape["size"], shape["type"]          if etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - ex) ** 2 + (y - ey) ** 2)             if distance < (size + esize):                   return True  # Overlap detected          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - ex) < (size + esize) and abs(y - ey) < (size + esize):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw filled circle     return np.pi * (size ** 2)  # Compute area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_left = (center[0] - size, center[1] - size)     bottom_right = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_left, bottom_right, color, -1)  # Draw filled square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle_cnt = np.array([point1, point2, point3])  # Convert to NumPy array     cv2.fillPoly(image, [triangle_cnt], color)  # Draw filled triangle      # Compute triangle area (equilateral)     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height  # (1/2 * base * height)   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []  # To store details of added shapes      # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Avoid infinite loops         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps with existing ones             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store shape metadata                 shapes_metadata.append({"type": shape_type, "center": center, "size": size, "area": area})                 break  # Move to the next shape          # Resize the image to num_pixels x num_pixels     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     # Extract areas of circles and squares     max_circle_area = max((shape["area"] for shape in shapes_metadata if shape["type"] == "circle"), default=0)     max_square_area = max((shape["area"] for shape in shapes_metadata if shape["type"] == "square"), default=0)      # Compare areas     if max_square_area > (1 + fraction) * max_circle_area:         return 0  # Square is much larger     elif max_circle_area > (1 + fraction) * max_square_area:         return 2  # Circle is much larger     else:         return 1  # They are similar in size  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     # Step 1: Generate a color palette     color_palette = generate_color_palette(num_colors)      # Step 2: Initialize storage     X = np.zeros((num_samples, num_pixels, num_pixels, 3), dtype=np.uint8)  # Image storage     y = np.zeros(num_samples, dtype=np.int32)  # Label storage      # Step 3: Generate images and labels     for i in range(num_samples):         image, shapes_metadata = generate_image(img_size, num_pixels, color_palette, max_shapes)         label = assign_label(shapes_metadata, fraction)                  # Store results         X[i] = image         y[i] = label          # Print progress         if i % 100 == 0:             print(f"Generated {i}/{num_samples} images...")      print("Dataset generation complete!")     return X, y  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     unique_labels = np.unique(y)  # Get all unique class labels     num_classes = len(unique_labels)      fig, axes = plt.subplots(num_classes, num_samples, figsize=(num_samples * 2, num_classes * 2))          for i, label in enumerate(unique_labels):         # Get indices of images belonging to the current class         indices = np.where(y == label)[0]                  # Select `num_samples` images randomly (or fewer if not enough available)         selected_indices = np.random.choice(indices, min(num_samples, len(indices)), replace=False)          for j, idx in enumerate(selected_indices):             ax = axes[i, j] if num_classes > 1 else axes[j]  # Adjust for 1-row cases             ax.imshow(X[idx])  # Display the image             ax.axis("off")  # Hide axis             ax.set_title(f"Label: {label}", fontsize=10)      plt.tight_layout()     plt.show()      save_history()
2025-03-25-21-22-42 163 41 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 42 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 43 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 44 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 45 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 46 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 47 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 48 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 49 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 50 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 51 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
2025-03-25-21-22-42 163 52 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mask = (y == 0) | (y == 2)     X_filtered, y_filtered = X[mask], y[mask]          # Remap label 2 to 1     y_filtered = np.where(y_filtered == 2, 1, y_filtered)          # Get indices for each class     indices_0 = np.where(y_filtered == 0)[0]     indices_1 = np.where(y_filtered == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(indices_0), len(indices_1))     sampled_indices_0 = np.random.choice(indices_0, min_size, replace=False)     sampled_indices_1 = np.random.choice(indices_1, min_size, replace=False)          # Combine and shuffle     balanced_indices = np.concatenate([sampled_indices_0, sampled_indices_1])     np.random.shuffle(balanced_indices)          return X_filtered[balanced_indices], y_filtered[balanced_indices]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative true positives     cumulative_tp = np.cumsum(sorted_targets)     total_positives = np.sum(targets)          # Compute TPR values     tpr_values = cumulative_tp / total_positives if total_positives > 0 else np.zeros_like(cumulative_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_indices = np.argsort(-preds)     sorted_targets = targets[sorted_indices]          # Compute cumulative false positives     cumulative_fp = np.cumsum(1 - sorted_targets)     total_negatives = np.sum(1 - targets)          # Compute FPR values     fpr_values = cumulative_fp / total_negatives if total_negatives > 0 else np.zeros_like(cumulative_fp)          return fpr_values  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     return np.trapz(TPR, FPR)  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     tpr_all = np.array([true_positive_rate_func(scores, y_test) for scores in scores_list])     fpr_all = np.array([false_positive_rate_func(scores, y_test) for scores in scores_list])      tpr_low = np.quantile(tpr_all, low_quantile, axis=0)     tpr_high = np.quantile(tpr_all, high_quantile, axis=0)     tpr_mid = np.median(tpr_all, axis=0)     fpr_median = np.median(fpr_all, axis=0)      return tpr_low.tolist(), tpr_high.tolist(), tpr_mid.tolist(), fpr_median.tolist()   def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     plt.figure(figsize=(8, 6))     plt.plot(fpr, tpr_mid, marker='o', linestyle='-', color='black', label="Median TPR")     plt.fill_between(fpr, tpr_low, tpr_high, color='b', alpha=0.3, label='Confidence Interval')     plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Random Classifier")     plt.xlabel('False Positive Rate (FPR)')     plt.ylabel('True Positive Rate (TPR)')     plt.title(f"AUC ROC: {compute_auc_func(tpr_mid, fpr):.2f}")     plt.legend(loc="lower right")     plt.grid()     plt.show()      save_history()
2025-03-25-21-22-42 163 53 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 54 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 55 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 56 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 57 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 58 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-25-21-22-42 163 59 test_tpr_low = [0.04, 0.73, 0.86, 0.91, 1] test_tpr_high = [0.30, 0.91, 0.95, 1.0, 1] test_tpr_mid = [0.08, 0.82, 0.91, 0.95, 1] test_fpr = [0.0, 0.25, 0.51, 0.77, 1]  plot_roc(np.array(test_tpr_low), np.array(test_tpr_high), np.array(test_tpr_mid), np.array(test_fpr), compute_auc)      
2025-03-25-21-22-42 163 60 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_area = np.sum(areas)          if total_area == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     features = compute_color_features(patch, ignore_color)     return aggregate_features(features)  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     h, w, _ = image.shape     patch_h, patch_w = h // grid_size, w // grid_size          descriptors = np.zeros((grid_size, grid_size, 7))          for i in range(grid_size):         for j in range(grid_size):             patch = image[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]             descriptors[i, j] = compute_patch_descriptor(patch, ignore_color)          return descriptors  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     descriptors1 = compute_image_patch_descriptors(image1, grid_size, ignore_color)     descriptors2 = compute_image_patch_descriptors(image2, grid_size, ignore_color)          total_similarity = np.sum(np.exp(-np.linalg.norm(descriptors1[:, :, None, :] - descriptors2[None, None, :, :], axis=-1)))     return total_similarity   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     raise NotImplementedError()  save_history()
2025-03-25-21-22-42 163 61 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 62 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_colors = np.unique(patch.reshape(-1, 3), axis=0)          features_list = []          for color in unique_colors:         if np.array_equal(color, ignore_color):             continue                  mask = np.all(patch == color, axis=-1)         y_indices, x_indices = np.where(mask)                  if len(y_indices) == 0:             continue                  area = len(y_indices)         centroid_x = np.mean(x_indices)         centroid_y = np.mean(y_indices)         variance_x = np.var(x_indices)         variance_y = np.var(y_indices)         skewness_x = np.mean((x_indices - centroid_x) ** 3) / (np.std(x_indices) ** 3 + 1e-6)         skewness_y = np.mean((y_indices - centroid_y) ** 3) / (np.std(y_indices) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         features_list.append(feature_vector)          return features_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_area = np.sum(areas)          if total_area == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     features = compute_color_features(patch, ignore_color)     return aggregate_features(features)  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     h, w, _ = image.shape     patch_h, patch_w = h // grid_size, w // grid_size          descriptors = np.zeros((grid_size, grid_size, 7))          for i in range(grid_size):         for j in range(grid_size):             patch = image[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]             descriptors[i, j] = compute_patch_descriptor(patch, ignore_color)          return descriptors  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     descriptors1 = compute_image_patch_descriptors(image1, grid_size, ignore_color)     descriptors2 = compute_image_patch_descriptors(image2, grid_size, ignore_color)          total_similarity = np.sum(np.exp(-np.linalg.norm(descriptors1[:, :, None, :] - descriptors2[None, None, :, :], axis=-1)))     return total_similarity   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     n1, n2 = X1.shape[0], X2.shape[0]     kernel_matrix = np.zeros((n1, n2))      # Step 1: Compute and cache descriptors for all images in X1 and X2     descriptors1 = [compute_image_patch_descriptors(X1[i].reshape((num_pixels, num_pixels, 3)), grid_size, ignore_color) for i in range(n1)]     descriptors2 = [compute_image_patch_descriptors(X2[j].reshape((num_pixels, num_pixels, 3)), grid_size, ignore_color) for j in range(n2)]      # Step 2: Flatten descriptors for distance-based kernel     flat1 = [desc.flatten() for desc in descriptors1]     flat2 = [desc.flatten() for desc in descriptors2]      # Step 3: Estimate sigma from a small subset (optional but helps)     sample_size_i = min(10, n1)     sample_size_j = min(10, n2)     distances = [np.linalg.norm(flat1[i] - flat2[j]) for i in range(sample_size_i) for j in range(sample_size_j)]     sigma = np.mean(distances) if distances else 1.0     sigma = max(sigma, 1e-5)      # Step 4: Compute RBF kernel matrix     for i in range(n1):         for j in range(n2):             dist = np.linalg.norm(flat1[i] - flat2[j])             kernel_matrix[i, j] = np.exp(-dist**2 / (2 * sigma**2))      return kernel_matrix  save_history()
2025-03-25-21-22-42 163 63 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 64 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 65 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 66 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 67 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 68 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-25-21-22-42 163 69 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     raise NotImplementedError()  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     raise NotImplementedError()   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         raise NotImplementedError()          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         raise NotImplementedError()  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         raise NotImplementedError()  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
2025-03-25-21-22-42 163 70 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     exp_x = np.exp(x - np.max(x))  # Stability trick to prevent overflow     return exp_x / np.sum(exp_x)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     raise NotImplementedError()   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         raise NotImplementedError()          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         raise NotImplementedError()  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         raise NotImplementedError()  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
2025-03-25-21-22-42 163 71 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     exp_x = np.exp(x - np.max(x))  # Stability trick to prevent overflow     return exp_x / np.sum(exp_x)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     H, W = image.shape     kH, kW = kernel.shape     output = np.zeros((H - kH + 1, W - kW + 1))      kernel_flipped = np.flipud(np.fliplr(kernel))      for i in range(output.shape[0]):         for j in range(output.shape[1]):             output[i, j] = np.sum(image[i:i+kH, j:j+kW] * kernel_flipped)          return output   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         raise NotImplementedError()          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         raise NotImplementedError()  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         raise NotImplementedError()  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
2025-03-25-21-22-42 163 72 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     exp_x = np.exp(x - np.max(x))  # Stability trick to prevent overflow     return exp_x / np.sum(exp_x)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     H, W = image.shape     kH, kW = kernel.shape     output = np.zeros((H - kH + 1, W - kW + 1))      kernel_flipped = np.flipud(np.fliplr(kernel))      for i in range(output.shape[0]):         for j in range(output.shape[1]):             output[i, j] = np.sum(image[i:i+kH, j:j+kW] * kernel_flipped)          return output   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         self.num_filters = num_filters         self.kernel_size = kernel_size         self.input_channels = input_channels                  # He Initialization: Scale computed based on input dimensions         scale = np.sqrt(2.0 / (kernel_size * kernel_size * input_channels))         self.filters = np.random.randn(num_filters, input_channels, kernel_size, kernel_size) * scale          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         raise NotImplementedError()  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         raise NotImplementedError()  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
2025-03-25-21-22-42 163 73 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     exp_x = np.exp(x - np.max(x))  # Stability trick to prevent overflow     return exp_x / np.sum(exp_x)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     H, W = image.shape     kH, kW = kernel.shape     output = np.zeros((H - kH + 1, W - kW + 1))      kernel_flipped = np.flipud(np.fliplr(kernel))      for i in range(output.shape[0]):         for j in range(output.shape[1]):             output[i, j] = np.sum(image[i:i+kH, j:j+kW] * kernel_flipped)          return output   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         self.num_filters = num_filters         self.kernel_size = kernel_size         self.input_channels = input_channels                  # He Initialization: Scale computed based on input dimensions         scale = np.sqrt(2.0 / (kernel_size * kernel_size * input_channels))         self.filters = np.random.randn(num_filters, input_channels, kernel_size, kernel_size) * scale          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         H, W, C = input_image.shape         output_height = H - self.kernel_size + 1         output_width = W - self.kernel_size + 1         output_maps = np.zeros((self.num_filters, output_height, output_width))                  for f in range(self.num_filters):             conv_sum = np.zeros((output_height, output_width))             for ch in range(C):                 conv_sum += conv2d_numpy(input_image[:, :, ch], self.filters[f, ch])             output_maps[f] = conv_sum                  return output_maps  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         raise NotImplementedError()  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
2025-03-25-21-22-42 163 74 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     exp_x = np.exp(x - np.max(x))  # Stability trick to prevent overflow     return exp_x / np.sum(exp_x)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     H, W = image.shape     kH, kW = kernel.shape     output = np.zeros((H - kH + 1, W - kW + 1))      kernel_flipped = np.flipud(np.fliplr(kernel))      for i in range(output.shape[0]):         for j in range(output.shape[1]):             output[i, j] = np.sum(image[i:i+kH, j:j+kW] * kernel_flipped)          return output   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         self.num_filters = num_filters         self.kernel_size = kernel_size         self.input_channels = input_channels                  # He Initialization: Scale computed based on input dimensions         scale = np.sqrt(2.0 / (kernel_size * kernel_size * input_channels))         self.filters = np.random.randn(num_filters, input_channels, kernel_size, kernel_size) * scale          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         H, W, C = input_image.shape         output_height = H - self.kernel_size + 1         output_width = W - self.kernel_size + 1         output_maps = np.zeros((self.num_filters, output_height, output_width))                  for f in range(self.num_filters):             conv_sum = np.zeros((output_height, output_width))             for ch in range(C):                 conv_sum += conv2d_numpy(input_image[:, :, ch], self.filters[f, ch])             output_maps[f] = conv_sum                  return output_maps  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         self.pool_size = pool_size              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         raise NotImplementedError()  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
2025-03-25-21-22-42 163 75 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     exp_x = np.exp(x - np.max(x))  # Stability trick to prevent overflow     return exp_x / np.sum(exp_x)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     H, W = image.shape     kH, kW = kernel.shape     output = np.zeros((H - kH + 1, W - kW + 1))      kernel_flipped = np.flipud(np.fliplr(kernel))      for i in range(output.shape[0]):         for j in range(output.shape[1]):             output[i, j] = np.sum(image[i:i+kH, j:j+kW] * kernel_flipped)          return output   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         self.num_filters = num_filters         self.kernel_size = kernel_size         self.input_channels = input_channels                  # He Initialization: Scale computed based on input dimensions         scale = np.sqrt(2.0 / (kernel_size * kernel_size * input_channels))         self.filters = np.random.randn(num_filters, input_channels, kernel_size, kernel_size) * scale          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         H, W, C = input_image.shape         output_height = H - self.kernel_size + 1         output_width = W - self.kernel_size + 1         output_maps = np.zeros((self.num_filters, output_height, output_width))                  for f in range(self.num_filters):             conv_sum = np.zeros((output_height, output_width))             for ch in range(C):                 conv_sum += conv2d_numpy(input_image[:, :, ch], self.filters[f, ch])             output_maps[f] = conv_sum                  return output_maps  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         self.pool_size = pool_size              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         H, W, C = input_image.shape         pooled_H, pooled_W = H // self.pool_size, W // self.pool_size         pooled_output = np.zeros((pooled_H, pooled_W, C))                  for i in range(pooled_H):             for j in range(pooled_W):                 pooled_output[i, j, :] = np.max(                     input_image[i*self.pool_size:(i+1)*self.pool_size,                                 j*self.pool_size:(j+1)*self.pool_size, :], axis=(0, 1))         return pooled_output  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         raise NotImplementedError()  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         raise NotImplementedError()              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         raise NotImplementedError()              def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         raise NotImplementedError()      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         raise NotImplementedError()          save_history()
