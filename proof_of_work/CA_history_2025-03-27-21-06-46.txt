2025-03-27-21-06-46 168 1 get_ipython().run_line_magic('matplotlib', 'inline') import matplotlib.pyplot as plt import numpy as np import scipy as sp import cv2 import random import pandas as pd from typing import List, Tuple, Callable, Optional from submission_utils import save_history, check_and_prepare_for_submission # import warnings filter from warnings import simplefilter # ignore all future warnings simplefilter(action='ignore', category=FutureWarning)
2025-03-27-21-06-46 168 2 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set() # Use set to ensure generated colours are unique          while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3)) # Generate RBG values with a medium brightness range         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA) # Use interpolation which helps to shrinking images  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         eX, eY, size, Etype = shape["center"][0], shape["center"][1], shape["size"], shape["Etype"]          if Etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - eX) ** 2 + (y - eY) ** 2)             if distance < (size + size):                   return True  # Return if this close to another circle          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - eX) < (size + size) and abs(y - eY) < (size + size):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw circle     return np.pi * (size ** 2)  # Calculate area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_lf = (center[0] - size, center[1] - size)     bottom_rg = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_lf, bottom_rg, color, -1)  # Draw square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle = np.array([point1, point2, point3])      cv2.fillPoly(image, [triangle], color)  # Draw filled triangle      # Calculate triangle area     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     # Start with a white image     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []       # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Limit retries to avoid infinite loop         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store metadata                 shapes_metadata.append({"Etype": shape_type, "center": center, "size": size, "area": area})                 break          # Resize the image     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     # Extract areas of circles and squares     max_circle = max((shape["area"] for shape in shapes_metadata if shape["Etype"] == "circle"), default=0)     max_square = max((shape["area"] for shape in shapes_metadata if shape["Etype"] == "square"), default=0)      # Label based on relative dominace     if max_square > (1 + fraction) * max_circle:         return 0     elif max_circle > (1 + fraction) * max_square:         return 2     else:         return 1  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     # Generate a color palette     color_palette = generate_color_palette(num_colors)      # Initialise storage for images and their labels     X = np.zeros((num_samples, num_pixels, num_pixels, 3), dtype=np.uint8)  # Image storage     y = np.zeros(num_samples, dtype=np.int32)  # Label storage      # Generate each sample     for i in range(num_samples):         image, shapes_metadata = generate_image(img_size, num_pixels, color_palette, max_shapes)         label = assign_label(shapes_metadata, fraction)                  # Store results         X[i] = image         y[i] = label      return X, y  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     unique_lb = np.unique(y)     num_classes = len(unique_lb)      fig, axes = plt.subplots(num_classes, num_samples, figsize=(num_samples * 2, num_classes * 2))          for i, label in enumerate(unique_lb):         # Get index of images belonging to the current class         index = np.where(y == label)[0]                   selected_indices = np.random.choice(index, min(num_samples, len(index)), replace=False)          for j, idx in enumerate(selected_indices):             ax = axes[i, j] if num_classes > 1 else axes[j]             ax.imshow(X[idx])              ax.axis("off")              ax.set_title(f"Label: {label}", fontsize=10)      plt.tight_layout()     plt.show()      save_history()
2025-03-27-21-06-46 168 3 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 4 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 5 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 6 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 7 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 8 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 9 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 10 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 11 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 12 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 13 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
2025-03-27-21-06-46 168 14 def filter_dataset(X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:     """     Filters the dataset to only include samples with labels 0 and 2,     remaps label 2 to 1, and then balances the dataset so that both classes     are represented equally.          Parameters:     - X (np.ndarray): Input images.     - y (np.ndarray): Corresponding labels.          Returns:     - Tuple[np.ndarray, np.ndarray]: Balanced images and remapped labels.     """     # YOUR CODE HERE     mk = (y == 0) | (y == 2) # Keep sample with label 0 or 2     X_fl, y_fl = X[mk], y[mk]          # Remap label 2 to 1 to have a binary classification     y_fl = np.where(y_fl == 2, 1, y_fl)          # Get index for each class     idx0 = np.where(y_fl == 0)[0]     idx_1 = np.where(y_fl == 1)[0]          # Balance dataset by taking the minimum class count     min_size = min(len(idx0), len(idx_1))     spl_idx0 = np.random.choice(idx0, min_size, replace=False)     spl_idx1 = np.random.choice(idx_1, min_size, replace=False)          # Combine index and shuffle to change order     balanced_idx = np.concatenate([spl_idx0, spl_idx1])     np.random.shuffle(balanced_idx)          return X_fl[balanced_idx], y_fl[balanced_idx]    def true_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the True Positive Rate (TPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_idx = np.argsort(-preds)     sorted_tg = targets[sorted_idx]          # Calculate cumulative true positives     sum_tp = np.cumsum(sorted_tg)     total_ps = np.sum(targets)          # Normalise to get TPR values     tpr_values = sum_tp / total_ps if total_ps > 0 else np.zeros_like(sum_tp)          return tpr_values  def false_positive_rate(preds: np.ndarray, targets: np.ndarray) -> np.ndarray:     """Computes the False Positive Rate (FPR) for given predictions and targets."""     # YOUR CODE HERE     # Sort predictions in descending order     sorted_idx = np.argsort(-preds)     sorted_tg = targets[sorted_idx]          # Calculate cumulative false positives     sum_fp = np.cumsum(1 - sorted_tg)     total_ng = np.sum(1 - targets)          # Normalise to get FPR values     fpr_values = sum_fp / total_ng if total_ng > 0 else np.zeros_like(sum_fp)          return fpr_values  def compute_auc(TPR: np.ndarray, FPR: np.ndarray) -> float:     """Computes the Area Under the Curve (AUC) for given TPR and FPR values."""     # YOUR CODE HERE     return np.trapz(TPR, FPR) # Use the ROC curve using trapezoidal rule  def compute_tpr_fpr_range(     scores_list: List[np.ndarray],      y_test: np.ndarray,      false_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      true_positive_rate_func: Callable[[np.ndarray, np.ndarray], np.ndarray],      low_quantile: float,      high_quantile: float ) -> Tuple[List[float], List[float], List[float], List[float]]:     """     Computes the true positive rate (TPR) and false positive rate (FPR) ranges     for multiple score distributions.      Returns:         - tpr_low: TPR at the `low_quantile`         - tpr_high: TPR at the `high_quantile`         - tpr_mid: Median TPR         - fpr: List of false positive rates     """     # YOUR CODE HERE     # Calculate TPR and FPR for ach score array     tpr_all = np.array([true_positive_rate_func(scores, y_test) for scores in scores_list])     fpr_all = np.array([false_positive_rate_func(scores, y_test) for scores in scores_list])      # Get confidence bound for TPR     tpr_low = np.quantile(tpr_all, low_quantile, axis=0)     tpr_high = np.quantile(tpr_all, high_quantile, axis=0)     tpr_mid = np.median(tpr_all, axis=0)          fpr_median = np.median(fpr_all, axis=0) # Use median FPR (it helps if score thresholds are fixed)      return tpr_low.tolist(), tpr_high.tolist(), tpr_mid.tolist(), fpr_median.tolist()   def plot_roc(     tpr_low: List[float],      tpr_high: List[float],      tpr_mid: List[float],      fpr: List[float],      compute_auc_func: Callable[[List[float], List[float]], float] ) -> None:     """     Plots the ROC curve with confidence intervals.      Parameters:         - tpr_low: Lower bound TPR values         - tpr_high: Upper bound TPR values         - tpr_mid: Median TPR values         - fpr: False positive rate values         - compute_auc_func: Function to compute AUC score     """     # YOUR CODE HERE     # Plot Roc Figure     plt.figure(figsize=(8, 6))     plt.plot(fpr, tpr_mid, linestyle='--', marker='o', color='black', label="Median TPR")     plt.fill_between(fpr, tpr_low, tpr_high, color='blue', alpha=0.3, label='Confidence Interval')     plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Random Classifier")     plt.xlabel('False Positive Rate (FPR)')     plt.ylabel('True Positive Rate (TPR)')     plt.title(f"AUC ROC: {compute_auc_func(tpr_mid, fpr):.2f}")     plt.legend()     plt.grid()     plt.show()      save_history()
2025-03-27-21-06-46 168 15 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 16 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-27-21-06-46 168 17 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-27-21-06-46 168 18 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-27-21-06-46 168 19 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-27-21-06-46 168 20 # This cell is reserved for the unit tests. Do not consider this cell. 
2025-03-27-21-06-46 168 21 test_tpr_low = [0.04, 0.73, 0.86, 0.91, 1] test_tpr_high = [0.30, 0.91, 0.95, 1.0, 1] test_tpr_mid = [0.08, 0.82, 0.91, 0.95, 1] test_fpr = [0.0, 0.25, 0.51, 0.77, 1]  plot_roc(np.array(test_tpr_low), np.array(test_tpr_high), np.array(test_tpr_mid), np.array(test_fpr), compute_auc)      
2025-03-27-21-06-46 168 22 def compute_color_features(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> List[np.ndarray]:     """     Extracts color-based spatial features from an image patch.          Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         List[np.ndarray]: A list of feature vectors, each describing a unique color in the patch.     """     # YOUR CODE HERE     h, w, _ = patch.shape     unique_col = np.unique(patch.reshape(-1, 3), axis=0) # Look for unique colour in the path          ft_list = []          for color in unique_col:         if np.array_equal(color, ignore_color): # Skip the background or ignored color             continue                  mk = np.all(patch == color, axis=-1) # Create binary mask for actual color         y_idx, x_idx = np.where(mk)                  if len(y_idx) == 0: # Skip look if not pixels found             continue         # Calculate shape and spatial distribution         area = len(y_idx)         centroid_x = np.mean(x_idx)         centroid_y = np.mean(y_idx)         variance_x = np.var(x_idx)         variance_y = np.var(y_idx)         skewness_x = np.mean((x_idx - centroid_x) ** 3) / (np.std(x_idx) ** 3 + 1e-6)         skewness_y = np.mean((y_idx - centroid_y) ** 3) / (np.std(y_idx) ** 3 + 1e-6)                  feature_vector = np.array([area, centroid_x, centroid_y, variance_x, variance_y, skewness_x, skewness_y])         ft_list.append(feature_vector)          return ft_list  def aggregate_features(features: List[np.ndarray]) -> np.ndarray:     """     Aggregates color-based features into a single patch descriptor.          Parameters:         features (List[np.ndarray]): A list of feature vectors.      Returns:         np.ndarray: A 7-dimensional aggregated feature vector.     """     # YOUR CODE HERE     if len(features) == 0:         return np.zeros(7)          features = np.vstack(features)     areas = features[:, 0]     total_a = np.sum(areas)          if total_a == 0:         return np.zeros(7)          weighted_sum = np.sum(features * areas[:, None], axis=0) / total_a # Weighted average of all features, weighted by area     return weighted_sum  def compute_patch_descriptor(patch: np.ndarray, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes a single descriptor for an image patch by aggregating color features.      Parameters:         patch (np.ndarray): The input patch of shape (H, W, 3).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: A 7-dimensional descriptor representing the patch.     """     # YOUR CODE HERE     features = compute_color_features(patch, ignore_color)     return aggregate_features(features)  def compute_image_patch_descriptors(image: np.ndarray, grid_size: int, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Computes descriptors for an entire image by dividing it into a grid of patches.      Parameters:         image (np.ndarray): The input image of shape (H, W, 3).         grid_size (int): Number of patches per row/column.         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         np.ndarray: An array of shape (grid_size, grid_size, 7) containing feature descriptors.     """     # YOUR CODE HERE     h, w, _ = image.shape     patch_h, patch_w = h // grid_size, w // grid_size          descriptors = np.zeros((grid_size, grid_size, 7)) # Initialise the descriptor grid          for i in range(grid_size):         for j in range(grid_size):             patch = image[i*patch_h:(i+1)*patch_h, j*patch_w:(j+1)*patch_w, :]             descriptors[i, j] = compute_patch_descriptor(patch, ignore_color)          return descriptors  def grid_based_set_kernel(image1: np.ndarray, image2: np.ndarray, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> float:     """     Computes the total similarity between two images by comparing each patch descriptor     in one image with every patch descriptor in the other image.      Parameters:         image1 (np.ndarray): First image of shape (H, W, 3).         image2 (np.ndarray): Second image of shape (H, W, 3).         grid_size (int): Number of patches per row/column (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore (default: white).      Returns:         float: The total similarity value computed as the sum of all pairwise similarities.     """     # YOUR CODE HERE     # Calculate pairwise similarities     descriptors1 = compute_image_patch_descriptors(image1, grid_size, ignore_color)     descriptors2 = compute_image_patch_descriptors(image2, grid_size, ignore_color)     # Apply RBF kernel to all distances and sum up     total_siml = np.sum(np.exp(-np.linalg.norm(descriptors1[:, :, None, :] - descriptors2[None, None, :, :], axis=-1)))     return total_siml   def kernel_func(X1: np.ndarray, X2: np.ndarray, num_pixels: int = 64, grid_size: int = 5, ignore_color: Tuple[int, int, int] = (255, 255, 255)) -> np.ndarray:     """     Custom kernel function for SVM that computes a grid-based set kernel.          Parameters:         X1 (np.ndarray): Array of vectorized images (n1, num_pixels*num_pixels*3).         X2 (np.ndarray): Array of vectorized images (n2, num_pixels*num_pixels*3).         num_pixels (int): The height/width of the original square images (default: 64).         grid_size (int): Number of patches per row/column for the grid-based descriptor (default: 5).         ignore_color (Tuple[int, int, int]): Color to ignore when computing descriptors (default: white).      Returns:         np.ndarray: Kernel matrix of shape (n1, n2) computed by averaging the similarities of patch descriptors between the two images.     """     # YOUR CODE HERE     n1, n2 = X1.shape[0], X2.shape[0]     kernel_matrix = np.zeros((n1, n2))      # Calculate descriptors onece per image     descriptors1 = [compute_image_patch_descriptors(X1[i].reshape((num_pixels, num_pixels, 3)), grid_size, ignore_color) for i in range(n1)]     descriptors2 = [compute_image_patch_descriptors(X2[j].reshape((num_pixels, num_pixels, 3)), grid_size, ignore_color) for j in range(n2)]      # Flatten descriptors for distance-based kernel     flat1 = [desc.flatten() for desc in descriptors1]     flat2 = [desc.flatten() for desc in descriptors2]      # Estimate sigma using a subset of distances     sample_i = min(10, n1)     sample_j = min(10, n2)     distances = [np.linalg.norm(flat1[i] - flat2[j]) for i in range(sample_i) for j in range(sample_j)]     sigma = np.mean(distances) if distances else 1.0     sigma = max(sigma, 1e-5)      # Calculate RBF kernel value for each image     for i in range(n1):         for j in range(n2):             dist = np.linalg.norm(flat1[i] - flat2[j])             kernel_matrix[i, j] = np.exp(-dist**2 / (2 * sigma**2))      return kernel_matrix  save_history()
2025-03-27-21-06-46 168 23 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 24 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 25 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 26 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 27 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 28 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 29 def relu(x: np.ndarray) -> np.ndarray:     """     Applies the ReLU activation function element-wise.          Parameters:         x (np.ndarray): Input array.      Returns:         np.ndarray: ReLU-activated output.     """     # YOUR CODE HERE     return np.maximum(0, x)  def softmax(x: np.ndarray) -> np.ndarray:     """     Applies the softmax function to convert logits into probabilities.          Parameters:         x (np.ndarray): Input logits.      Returns:         np.ndarray: Softmax probabilities.     """     # YOUR CODE HERE     ex = np.exp(x - np.max(x))  # Shift logits for numerical stability     return ex / np.sum(ex)  def conv2d_numpy(image: np.ndarray, kernel: np.ndarray) -> np.ndarray:     """     Computes the 2D convolution of an image with a kernel using NumPy.      Parameters:         image (np.ndarray): 2D input image array of shape (H, W).         kernel (np.ndarray): 2D filter kernel array of shape (kH, kW).      Returns:         np.ndarray: Output feature map of shape (H-kH+1, W-kW+1).     """     # YOUR CODE HERE     H, W = image.shape     kH, kW = kernel.shape     output = np.zeros((H - kH + 1, W - kW + 1))      kernel_flipped = np.flipud(np.fliplr(kernel)) # Flip kernel      for i in range(output.shape[0]): # Slide kernel over image         for j in range(output.shape[1]):             output[i, j] = np.sum(image[i:i+kH, j:j+kW] * kernel_flipped)          return output   class ConvLayer:     """     A simple 2D convolutional layer that applies learned filters to an input image.      This layer consists of `num_filters` different kernels, each of size `kernel_size x kernel_size`,     and processes an input with `input_channels` (e.g., RGB images have 3 channels).      Parameters:         num_filters (int): Number of filters in the convolutional layer.         kernel_size (int): Size of each square filter (e.g., 3x3 or 5x5).         input_channels (int, optional): Number of input channels (default is 3 for RGB images).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs the convolution operation on the input image.     """     def __init__(self, num_filters: int, kernel_size: int, input_channels: int = 3) -> None:         # YOUR CODE HERE         self.num_filters = num_filters         self.kernel_size = kernel_size         self.input_channels = input_channels                  # He initialisation for better training performance         scale = np.sqrt(2.0 / (kernel_size * kernel_size * input_channels))         self.filters = np.random.randn(num_filters, input_channels, kernel_size, kernel_size) * scale          def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of the convolutional layer.         """         # YOUR CODE HERE         H, W, C = input_image.shape         output_height = H - self.kernel_size + 1         output_width = W - self.kernel_size + 1         output_mp = np.zeros((self.num_filters, output_height, output_width))                  for f in range(self.num_filters):             conv_sum = np.zeros((output_height, output_width))             for ch in range(C):                 conv_sum += conv2d_numpy(input_image[:, :, ch], self.filters[f, ch])             output_mp[f] = conv_sum                  return output_mp  class MaxPoolLayer:     """     A 2D max pooling layer that reduces spatial dimensions while retaining important features.      Max pooling selects the maximum value within non-overlapping pooling regions,     effectively downsampling the feature map.      Parameters:         pool_size (int, optional): The size of the pooling window (default is 2x2).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs max pooling on the input feature map.     """      def __init__(self, pool_size: int = 2) -> None:         """         Max pooling layer with a fixed pool size.         """         # YOUR CODE HERE         self.pool_size = pool_size              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Forward pass of max pooling.         """         # YOUR CODE HERE         H, W, C = input_image.shape         pooled_H, pooled_W = H // self.pool_size, W // self.pool_size         pooled_output = np.zeros((pooled_H, pooled_W, C))                  for i in range(pooled_H):             for j in range(pooled_W):                 pooled_output[i, j, :] = np.max(                     input_image[i*self.pool_size:(i+1)*self.pool_size,                                 j*self.pool_size:(j+1)*self.pool_size, :], axis=(0, 1))         return pooled_output  class TwoLayerFullyConnected:     """     A simple two-layer fully connected neural network with ReLU activation.      This network consists of:     - A hidden layer with `hidden_size` neurons and ReLU activation.     - An output layer with `output_size` neurons (e.g., one per class).      Parameters:         input_size (int): Number of input features.         hidden_size (int): Number of neurons in the hidden layer.         output_size (int): Number of neurons in the output layer.      Methods:         forward(input_vector: np.ndarray) -> np.ndarray:             Computes a forward pass through the network.          backward(dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:             Performs backpropagation and updates weights using gradient descent.     """     def __init__(self, input_size: int, hidden_size: int, output_size: int) -> None:         """         A two-layer fully connected network with ReLU activation between layers.         """         # YOUR CODE HERE         self.input_size = input_size         self.hidden_size = hidden_size         self.output_size = output_size                  # He Initialisation         self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)         self.b1 = np.zeros(hidden_size)         self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)         self.b2 = np.zeros(output_size)      def forward(self, input_vector: np.ndarray) -> np.ndarray:         """         Forward pass through the fully connected layers.         """         # YOUR CODE HERE         self.input_vector = input_vector  # Store for backpropagation         self.z1 = np.dot(input_vector, self.W1) + self.b1         self.a1 = relu(self.z1)         self.z2 = np.dot(self.a1, self.W2) + self.b2         return softmax(self.z2)      def backward(self, dL_dout: np.ndarray, learning_rate: float) -> np.ndarray:         """         Backward pass through the fully connected layers.         """         # YOUR CODE HERE         # Calcaulate gradients for output layer         dL_dz2 = dL_dout          dL_dW2 = np.outer(self.a1, dL_dz2)          dL_db2 = dL_dz2          dL_da1 = np.dot(dL_dz2, self.W2.T)         dL_dz1 = dL_da1 * (self.z1 > 0)  # ReLU derivative          dL_dW1 = np.outer(self.input_vector, dL_dz1)         dL_db1 = dL_dz1          # Gradient step         if dL_dW1.shape == self.W1.shape and dL_dW2.shape == self.W2.shape:             self.W1 -= learning_rate * dL_dW1             self.b1 -= learning_rate * dL_db1             self.W2 -= learning_rate * dL_dW2             self.b2 -= learning_rate * dL_db2                  return dL_dz1  class SimpleCNN:     """     A basic convolutional neural network (CNN) for image classification.      The architecture consists of:     - A convolutional layer with `num_filters` filters of size `kernel_size`.     - A max pooling layer to reduce spatial dimensions.     - A fully connected layer for classification.      Parameters:         image_size (int, optional): The size of the input images (default is 50x50).         num_filters (int, optional): Number of filters in the convolutional layer (default is 8).         kernel_size (int, optional): Size of the convolutional filters (default is 3x3).         pool_size (int, optional): Size of the max pooling window (default is 2x2).         num_classes (int, optional): Number of output classes (default is 2).         hidden_size (int, optional): Number of neurons in the fully connected hidden layer (default is 64).      Methods:         forward(input_image: np.ndarray) -> np.ndarray:             Performs a forward pass through the network.          predict(X: np.ndarray) -> np.ndarray:             Computes class predictions for a batch of images.          fit(X_train: np.ndarray, y_train: np.ndarray, epochs: int, learning_rate: float) -> None:             Trains the CNN using gradient descent.     """      def __init__(self, image_size: int = 50, num_filters: int = 8, kernel_size: int = 3,                  pool_size: int = 2, num_classes: int = 2, hidden_size: int = 64) -> None:         """         A simple CNN classifier built from scratch.         """         # YOUR CODE HERE         self.image_size = image_size         self.num_filters = num_filters         self.kernel_size = kernel_size         self.pool_size = pool_size          # Define convolution and pooling layers         self.conv_layer = ConvLayer(num_filters, kernel_size)         self.pool_layer = MaxPoolLayer(pool_size)               self.fc_input_size = None # Will be set on first forward pass         self.fc = None         self.hidden_size = hidden_size         self.num_classes = num_classes              def forward(self, input_image: np.ndarray) -> np.ndarray:         """         Performs a forward pass through the CNN.         """         # YOUR CODE HERE         conv_out = self.conv_layer.forward(input_image)         activated = relu(conv_out)         pooled_out = self.pool_layer.forward(activated)          # Dynamically determine the input size for the fully connected layer         if self.fc is None:             self.fc_input_size = pooled_out.size  # Flattened size after pooling             self.fc = TwoLayerFullyConnected(self.fc_input_size, self.hidden_size, self.num_classes)          flattened = pooled_out.flatten()          return self.fc.forward(flattened)         def predict(self, X: np.ndarray) -> np.ndarray:         # YOUR CODE HERE         # Reshape input         if X.ndim == 2:             num_samples = X.shape[0]             img_area = X.shape[1] // 3             img_dim = int(np.sqrt(img_area))             X = X.reshape((num_samples, img_dim, img_dim, 3))         predictions = [np.argmax(self.forward(x)) for x in X]         return np.array(predictions)      def fit(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 10, learning_rate: float = 0.001) -> None:         # YOUR CODE HERE         if X_train.ndim == 2: # Reshape input             num_samples = X_train.shape[0]             img_area = X_train.shape[1] // 3             img_dim = int(np.sqrt(img_area))             X_train = X_train.reshape((num_samples, img_dim, img_dim, 3))         for epoch in range(epochs):             # Shuffle data at the start of each epoch             idx = np.random.permutation(len(X_train))             X_train = X_train[idx]             y_train = y_train[idx]                          loss = 0             correct = 0  # Track predictions                          for i in range(len(X_train)):                 y_pred = self.forward(X_train[i])                 y_true = np.zeros(y_pred.shape)                 y_true[y_train[i]] = 1                                  loss += np.sum((y_pred - y_true) ** 2)                 # Track accuracy                 if np.argmax(y_pred) == y_train[i]:                     correct += 1                                  dL_dout = y_pred - y_true                 self.fc.backward(dL_dout, learning_rate)          save_history()
2025-03-27-21-06-46 168 30 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 31 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 32 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 33 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 34 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 35 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 36 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 37 def baseline_majority_accuracy(y: np.ndarray) -> float:     """     Computes the baseline accuracy using the frequency of the majority class.          A naive classifier that always predicts the most frequent class      achieves an accuracy equal to the proportion of that class in the dataset.          Parameters:         y (np.ndarray): Array of true labels.          Returns:         float: The baseline majority class accuracy.     """     # YOUR CODE HERE     unique, counts = np.unique(y, return_counts=True) # Count how many times each class appears     freq_class = np.max(counts) # Get the most frequent class number     return freq_class / len(y)   def vectorize_images(X: np.ndarray) -> np.ndarray:     """     Reshapes an image dataset from (n, size, size, 3) to (n, size * size * 3).          Parameters:         X (np.ndarray): Input dataset of shape (n, size, size, 3).              Returns:         np.ndarray: Reshaped dataset of shape (n, size * size * 3).     """     # YOUR CODE HERE     return X.reshape(X.shape[0], -1)      def train_test_split(     X: np.ndarray,      y: np.ndarray,      test_size: float = 0.3,      random_state: Optional[int] = None ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:     """     Splits arrays or matrices into random train and test subsets.      Parameters:         X : np.ndarray             Feature matrix with shape (n_samples, n_features).         y : np.ndarray             Target vector with shape (n_samples, ) or (n_samples, n_outputs).         test_size : float, optional (default=0.3)             Proportion of the dataset to include in the test split.         random_state : int or None, optional (default=None)             Seed used by the random number generator.      Returns:         Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]             X_train, X_test, y_train, y_test     """     # YOUR CODE HERE     if random_state is not None:         np.random.seed(random_state)     # Get class distribution         uniq_classes, clss_counts = np.unique(y, return_counts=True)     split_idx = [int(count * (1 - test_size)) for count in clss_counts] # Determine slip index per class      X_train, X_test, y_train, y_test = [], [], [], []          for cls_idx, cls in enumerate(uniq_classes): # Get each class independently to maintain balance         class_msk = (y == cls)         X_cls, y_cls = X[class_msk], y[class_msk]         indices = np.random.permutation(len(y_cls)) # Shuffle class          # Split train and test         X_train.append(X_cls[indices[:split_idx[cls_idx]]])         y_train.append(y_cls[indices[:split_idx[cls_idx]]])         X_test.append(X_cls[indices[split_idx[cls_idx]:]])         y_test.append(y_cls[indices[split_idx[cls_idx]:]])      return np.vstack(X_train), np.vstack(X_test), np.hstack(y_train), np.hstack(y_test) # Get all combined results  def accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:     """     Compute the accuracy classification score.      Parameters:         y_true : np.ndarray             Ground truth (correct) target values.         y_pred : np.ndarray             Estimated targets as returned by a classifier.      Returns:         float: The fraction of correctly classified samples.     """     # YOUR CODE HERE     # Ensure the inputs are NumPy arrays     y_true = np.asarray(y_true)     y_pred = np.asarray(y_pred)      # Compute accuracy as the fraction of correct predictions     corr_prediction = np.sum(y_true == y_pred)     ttl_sample = len(y_true)          return corr_prediction / ttl_sample       save_history()
2025-03-27-21-06-46 168 38 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 39 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 40 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 41 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 42 num_colors = 2 num_pixels = 28 num_samples = 300 max_shapes = 1   X, y = generate_dataset(     num_samples=num_samples,      img_size=150,      num_pixels=num_pixels,      num_colors=num_colors,      fraction=2,      max_shapes=max_shapes) X,y = filter_dataset(X,y) display_sample_images(X, y, num_samples=5)  X = vectorize_images(X) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)  print('# instances per class: %s'%np.unique(y_test, return_counts=True)[1]) print('Baseline accuracy: %.3f'%baseline_majority_accuracy(y_test))  def fix_kernel_func(X1, X2):     return kernel_func(X1, X2, num_pixels=num_pixels, grid_size=5, ignore_color=(255, 255, 255))  from sklearn.svm import SVC svm = SVC(kernel=fix_kernel_func) svm.fit(X_train, y_train) y_pred = svm.predict(X_test)  accuracy = accuracy_score(y_test, y_pred) print(f"Grid-Based Set Kernel SVM Accuracy: {accuracy:.3f}")
2025-03-27-21-06-46 168 43 cnn = SimpleCNN(image_size=num_pixels, num_filters=8, hidden_size=32)  normalized_X_train = X_train.astype(np.float32) / 255.0 - 0.5 normalized_X_test = X_test.astype(np.float32) / 255.0 - 0.5  cnn.fit(normalized_X_train, y_train, epochs=20, learning_rate=1e-2) y_pred = cnn.predict(normalized_X_train) accuracy = accuracy_score(y_train, y_pred) print(f"Simple CNN accuracy on training set: {accuracy:.3f}%") y_pred = cnn.predict(normalized_X_test) accuracy = accuracy_score(y_test, y_pred) print(f"Simple CNN accuracy on test set: {accuracy:.3f}%")
2025-03-27-21-06-46 168 44 cnn = SimpleCNN(image_size=num_pixels, num_filters=8, hidden_size=32)  normalized_X_train = X_train.astype(np.float32) / 255.0 - 0.5 normalized_X_test = X_test.astype(np.float32) / 255.0 - 0.5  cnn.fit(normalized_X_train, y_train, epochs=20, learning_rate=1e-2) y_pred = cnn.predict(normalized_X_train) accuracy = accuracy_score(y_train, y_pred) print(f"Simple CNN accuracy on training set: {accuracy:.3f}%") y_pred = cnn.predict(normalized_X_test) accuracy = accuracy_score(y_test, y_pred) print(f"Simple CNN accuracy on test set: {accuracy:.3f}%")
2025-03-27-21-06-46 168 45 get_ipython().run_line_magic('matplotlib', 'inline') import matplotlib.pyplot as plt import numpy as np import scipy as sp import cv2 import random import pandas as pd from typing import List, Tuple, Callable, Optional from submission_utils import save_history, check_and_prepare_for_submission # import warnings filter from warnings import simplefilter # ignore all future warnings simplefilter(action='ignore', category=FutureWarning)
2025-03-27-21-06-46 168 46 def generate_color_palette(num_colors: int) -> List[Tuple[int, int, int]]:     """     Generates a color palette with a specified number of distinct colors.          Parameters:     - num_colors (int): Number of distinct colors to generate.          Returns:     - list of RGB tuples representing colors.     """     # YOUR CODE HERE     palette = set() # Use set to ensure generated colours are unique          while len(palette) < num_colors:         color = tuple(int(c) for c in np.random.randint(50, 206, size=3)) # Generate RBG values with a medium brightness range         palette.add(color)     return list(palette)  def scale_image(image: np.ndarray, num_pixels: int) -> np.ndarray:     """     Scales an image to the desired size.          Parameters:     - image (np.ndarray): The input image.     - num_pixels (int): Desired size for width and height.          Returns:     - np.ndarray: Rescaled image.     """     # YOUR CODE HERE     return cv2.resize(image, (num_pixels, num_pixels), interpolation=cv2.INTER_AREA) # Use interpolation which helps to shrinking images  def check_overlap(center: Tuple[int, int], size: int, existing_shapes: List[dict]) -> bool:     """     Checks if a new shape overlaps with existing shapes.          Parameters:     - center (Tuple[int, int]): Center of the new shape.     - size (int): Size of the new shape.     - existing_shapes (List[dict]): List of existing shapes.          Returns:     - bool: True if there is an overlap, False otherwise.     """     # YOUR CODE HERE     x, y = center          for shape in existing_shapes:         eX, eY, size, Etype = shape["center"][0], shape["center"][1], shape["size"], shape["Etype"]          if Etype == "circle":             # Use Euclidean distance for circle overlaps             distance = np.sqrt((x - eX) ** 2 + (y - eY) ** 2)             if distance < (size + size):                   return True  # Return if this close to another circle          else:  # Squares and Triangles (Bounding Box Method)             if abs(x - eX) < (size + size) and abs(y - eY) < (size + size):                 return True  # Overlap detected      return False  def draw_circle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a circle on an image.          Returns:     - float: Area of the circle.     """     # YOUR CODE HERE     cv2.circle(image, center, size, color, -1)  # Draw circle     return np.pi * (size ** 2)  # Calculate area  def draw_square(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> int:     """     Draws a square on an image.          Returns:     - int: Area of the square.     """     # YOUR CODE HERE     top_lf = (center[0] - size, center[1] - size)     bottom_rg = (center[0] + size, center[1] + size)     cv2.rectangle(image, top_lf, bottom_rg, color, -1)  # Draw square     return (2 * size) ** 2  # Compute area  def draw_triangle(image: np.ndarray, center: Tuple[int, int], size: int, color: Tuple[int, int, int]) -> float:     """     Draws a triangle on an image.          Returns:     - float: Area of the triangle.     """     # YOUR CODE HERE     # Define three triangle vertices     point1 = (center[0], center[1] - size)  # Top vertex     point2 = (center[0] - size, center[1] + size)  # Bottom-left vertex     point3 = (center[0] + size, center[1] + size)  # Bottom-right vertex          triangle = np.array([point1, point2, point3])      cv2.fillPoly(image, [triangle], color)  # Draw filled triangle      # Calculate triangle area     height = (np.sqrt(3) / 2) * (2 * size)     return 0.5 * (2 * size) * height   def generate_image(img_size: int, num_pixels: int, color_palette: List[Tuple[int, int, int]], max_shapes: int = 10) -> Tuple[np.ndarray, List[dict]]:     """     Generates an image with at least one circle, one square, and one triangle.     Uses helper functions for shape drawing and scaling.          Parameters:     - img_size (int): Size of the generated image before scaling.     - num_pixels (int): Final size of the image after scaling.     - color_palette (List[Tuple[int, int, int]]): List of available colors.          Returns:     - np.ndarray: Generated image.     - List[dict]: Metadata for shapes in the image.     """     # YOUR CODE HERE     # Start with a white image     image = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255     shapes_metadata = []       # Ensure we place at least 1 circle, 1 square, and 1 triangle     shape_types = ["circle", "square", "triangle"]          for shape_type in shape_types + random.choices(shape_types, k=max_shapes - len(shape_types)):  # Ensure min shapes, then random         max_attempts = 20  # Limit retries to avoid infinite loop         for _ in range(max_attempts):             # Generate a random position and size             center = (random.randint(20, img_size - 20), random.randint(20, img_size - 20))             size = random.randint(10, 30)             color = random.choice(color_palette)              # Check if this new shape overlaps             if not check_overlap(center, size, shapes_metadata):                 if shape_type == "circle":                     area = draw_circle(image, center, size, color)                 elif shape_type == "square":                     area = draw_square(image, center, size, color)                 else:                     area = draw_triangle(image, center, size, color)                                  # Store metadata                 shapes_metadata.append({"Etype": shape_type, "center": center, "size": size, "area": area})                 break          # Resize the image     image = scale_image(image, num_pixels)          return image, shapes_metadata  def assign_label(shapes_metadata: List[dict], fraction: float = 0.5) -> int:     """     Assigns a label based on a fractional comparison of the largest circle and square areas.          Returns:     - int: 0 if the largest square area is significantly larger than the largest circle area,            2 if the largest circle area is significantly larger than the largest square area,            1 otherwise.     """     # YOUR CODE HERE     # Extract areas of circles and squares     max_circle = max((shape["area"] for shape in shapes_metadata if shape["Etype"] == "circle"), default=0)     max_square = max((shape["area"] for shape in shapes_metadata if shape["Etype"] == "square"), default=0)      # Label based on relative dominace     if max_square > (1 + fraction) * max_circle:         return 0     elif max_circle > (1 + fraction) * max_square:         return 2     else:         return 1  def generate_dataset(num_samples: int, img_size: int, num_pixels: int, num_colors: int, fraction: float = 2.0, max_shapes: int = 10) -> Tuple[np.ndarray, np.ndarray]:     """     Generates a dataset of images and labels in memory.          Returns:     - tuple[np.ndarray, np.ndarray]: Images (X) and labels (y).     """     # YOUR CODE HERE     # Generate a color palette     color_palette = generate_color_palette(num_colors)      # Initialise storage for images and their labels     X = np.zeros((num_samples, num_pixels, num_pixels, 3), dtype=np.uint8)  # Image storage     y = np.zeros(num_samples, dtype=np.int32)  # Label storage      # Generate each sample     for i in range(num_samples):         image, shapes_metadata = generate_image(img_size, num_pixels, color_palette, max_shapes)         label = assign_label(shapes_metadata, fraction)                  # Store results         X[i] = image         y[i] = label      return X, y  def display_sample_images(X: np.ndarray, y: np.ndarray, num_samples: int = 5) -> None:     """     Displays randomly sampled images from the dataset with labels.     """     # YOUR CODE HERE     unique_lb = np.unique(y)     num_classes = len(unique_lb)      fig, axes = plt.subplots(num_classes, num_samples, figsize=(num_samples * 2, num_classes * 2))          for i, label in enumerate(unique_lb):         # Get index of images belonging to the current class         index = np.where(y == label)[0]                   selected_indices = np.random.choice(index, min(num_samples, len(index)), replace=False)          for j, idx in enumerate(selected_indices):             ax = axes[i, j] if num_classes > 1 else axes[j]             ax.imshow(X[idx])              ax.axis("off")              ax.set_title(f"Label: {label}", fontsize=10)      plt.tight_layout()     plt.show()      save_history()
2025-03-27-21-06-46 168 47 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 48 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 49 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 50 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 51 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 52 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 53 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 54 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 55 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 56 # This cell is reserved for the unit tests. Do not consider this cell.
2025-03-27-21-06-46 168 57 # Run the dataset generation X, y = generate_dataset(num_samples=1000, img_size=150, num_pixels=64, num_colors=3, fraction=2, max_shapes=5) display_sample_images(X, y, num_samples=5)
